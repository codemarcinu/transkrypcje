import streamlit as st
import os
import sys
import json
import glob
import threading
import shutil
from pathlib import Path
from typing import Optional

# Dodanie ≈õcie≈ºki projektu do sys.path, aby widzieƒá modu≈Çy src
project_root = Path(__file__).resolve().parent.parent.parent
sys.path.append(str(project_root))

from src.core.processor import ContentProcessor
from src.agents.writer import ReportWriter
from src.agents.extractor import KnowledgeExtractor
from src.utils.prompts_config import PROMPT_TEMPLATES
from src.utils.logger import setup_logger
from src.utils.config import (
    WHISPER_LANGUAGES, WHISPER_MODELS, DEFAULT_MODEL_SIZE,
    DATA_PROCESSED, DATA_OUTPUT, CHUNK_SIZE, OVERLAP, MODEL_EXTRACTOR
)
from src.utils.helpers import check_ffmpeg
from src.core.text_cleaner import clean_transcript
from src.utils.text_processing import smart_split_text
from src.core.llm_engine import unload_model

logger = setup_logger()

# Konfiguracja strony
st.set_page_config(
    page_title="AI Note Generator v2.0",
    page_icon="üéôÔ∏è",
    layout="wide"
)

# --- Helper Classes for Callbacks ---

class StreamlitProgress:
    def __init__(self, progress_bar, status_text):
        self.progress_bar = progress_bar
        self.status_text = status_text
        
        self.stage_map = {
            "downloading": "üì• Pobieranie wideo...",
            "converting": "üîÑ Przygotowywanie audio...",
            "transcribing": "üëÇ Przetwarzanie mowy (Whisper)...",
            "summarizing": "‚úçÔ∏è Generowanie podsumowania...",
            "content_generation": "üß† Bielik pisze rozdzia≈Ç podrƒôcznika...",
            "cleaning": "üßπ PorzƒÖdkowanie plik√≥w..."
        }
        
    def update(self, percent: float, stage: str, file_size: Optional[str] = None):
        val = min(max(percent / 100.0, 0.0), 1.0)
        self.progress_bar.progress(val)
        
        friendly_stage = self.stage_map.get(stage.lower(), f"Pracujƒô: {stage}")
        msg = f"Status: {friendly_stage}"
        if file_size:
            msg += f" | Rozmiar: {file_size}"
        self.status_text.text(msg)


def _process_single_file(processor, target_file_path, subtitle_path, output_path,
                         download_subs, do_transcribe, do_summarize,
                         lang_code, model_size, output_format, summary_style):
    """Przetwarza pojedynczy plik audio/video i zwraca (txt_file, json_file)."""
    txt_file = None
    json_file = None

    if target_file_path and os.path.exists(target_file_path):
        if download_subs and subtitle_path and os.path.exists(subtitle_path):
            txt_file = processor.convert_subtitles_to_txt(subtitle_path)
        elif do_transcribe:
            segments_gen, info = processor.transcribe_video(target_file_path, lang_code, model_size)
            output_base = os.path.join(output_path, os.path.basename(target_file_path))
            txt_file, json_file = processor.save_transcription(segments_gen, info, output_base, output_format, lang_code)

        if txt_file and os.path.exists(txt_file) and do_summarize:
            summary = processor.summarize_from_file(txt_file, style=summary_style)
            if summary:
                summary_path = os.path.splitext(txt_file)[0] + "_podsumowanie.txt"
                with open(summary_path, "w", encoding='utf-8') as f:
                    f.write(summary)

    return txt_file, json_file


def _run_knowledge_extraction(txt_file: str, progress_bar, status_text) -> Optional[str]:
    """
    Uruchamia ekstrakcjƒô wiedzy z pliku transkrypcji.
    Zwraca ≈õcie≈ºkƒô do pliku JSON lub None w przypadku b≈Çƒôdu.
    """
    if not txt_file or not os.path.exists(txt_file):
        return None

    try:
        # 1. Wczytaj i wyczy≈õƒá transkrypcjƒô
        status_text.text("üîç Przygotowywanie tekstu do analizy...")
        progress_bar.progress(0.05)

        with open(txt_file, 'r', encoding='utf-8') as f:
            raw_text = f.read()

        clean_text = clean_transcript(raw_text)
        chunks = smart_split_text(clean_text, chunk_size=CHUNK_SIZE, chunk_overlap=OVERLAP)

        if not chunks:
            status_text.text("‚ö†Ô∏è Brak tekstu do analizy")
            return None

        status_text.text(f"üì¶ Podzielono na {len(chunks)} fragment√≥w. Rozpoczynam ekstrakcjƒô...")
        progress_bar.progress(0.1)

        # 2. Ekstrakcja wiedzy
        knowledge_base = []
        extractor = KnowledgeExtractor()
        total_chunks = len(chunks)

        for i, chunk in enumerate(chunks):
            progress_pct = int(((i + 1) / total_chunks) * 100)
            time_tag = f"Part {i+1} ({progress_pct}%)"

            status_text.text(f"üß† Analizujƒô fragment {i+1}/{total_chunks}...")

            graph = extractor.extract_knowledge(chunk, chunk_id=time_tag)
            knowledge_base.append(graph.model_dump())

            # Update progress (10% start + 80% for extraction)
            extraction_progress = 0.1 + (0.8 * (i + 1) / total_chunks)
            progress_bar.progress(extraction_progress)

        # 3. Zapis JSON
        status_text.text("üíæ Zapisywanie bazy wiedzy...")
        progress_bar.progress(0.95)

        # Nazwa pliku JSON bazuje na nazwie transkrypcji
        base_name = os.path.basename(txt_file).replace('.txt', '')
        json_filename = f"{base_name}_kb.json"
        json_path = os.path.join(DATA_PROCESSED, json_filename)

        os.makedirs(DATA_PROCESSED, exist_ok=True)
        with open(json_path, 'w', encoding='utf-8') as f:
            json.dump(knowledge_base, f, ensure_ascii=False, indent=2)

        # 4. Zwolnij VRAM po ekstrakcji
        unload_model(MODEL_EXTRACTOR)

        progress_bar.progress(1.0)
        status_text.text(f"‚úÖ Ekstrakcja zako≈Ñczona! Zapisano: {json_filename}")

        return json_path

    except Exception as e:
        status_text.text(f"‚ùå B≈ÇƒÖd ekstrakcji: {e}")
        return None


def _extract_topic_from_filename(filename: str) -> str:
    """WyciƒÖga czytelny temat z nazwy pliku."""
    # Usu≈Ñ rozszerzenia i suffiksy
    topic = os.path.basename(filename)
    for suffix in ['.json', '.txt', '.mp4', '.mp3', '_transkrypcja', '_kb', '_podsumowanie']:
        topic = topic.replace(suffix, '')

    # Zamie≈Ñ separatory na spacje
    topic = topic.replace('_', ' ').replace('-', ' ')

    # Usu≈Ñ datƒô z poczƒÖtku (YYYY-MM-DD)
    import re
    topic = re.sub(r'^\d{4}\s*\d{2}\s*\d{2}\s*', '', topic)

    # Capitalize i przytnij
    return topic.strip().title()[:100]


def main():
    st.title("üéôÔ∏è AI Transkrypcja & Notatki v2.0")

    # Inicjalizacja Session State
    if 'selected_file_for_generation' not in st.session_state:
        st.session_state['selected_file_for_generation'] = None
    if 'last_generated_result' not in st.session_state:
        st.session_state['last_generated_result'] = None
    if 'last_extraction_json' not in st.session_state:
        st.session_state['last_extraction_json'] = None
    if 'last_topic_name' not in st.session_state:
        st.session_state['last_topic_name'] = None
    if 'go_to_lab' not in st.session_state:
        st.session_state['go_to_lab'] = False

    # --- SIDEBAR: KONFIGURACJA G≈Å√ìWNA ---
    with st.sidebar:
        st.header("‚öôÔ∏è Konfiguracja")
        
        # 1. Model Whisper
        st.subheader("üéôÔ∏è Model Whisper")
        language = st.selectbox(
            "Jƒôzyk audio:",
            options=list(WHISPER_LANGUAGES.keys()),
            index=list(WHISPER_LANGUAGES.keys()).index("Polski")
        )

        # Opisy modeli dla u≈ºytkownika
        model_descriptions = {
            "medium": "medium ‚Äî szybszy (~5 GB VRAM)",
            "large-v3": "large-v3 ‚Äî najlepsza jako≈õƒá (~8 GB VRAM)"
        }
        model_size = st.selectbox(
            "Wielko≈õƒá modelu:",
            options=WHISPER_MODELS,
            index=WHISPER_MODELS.index(DEFAULT_MODEL_SIZE),
            format_func=lambda x: model_descriptions.get(x, x),
            help="medium: dobry kompromis szybko≈õƒá/jako≈õƒá. large-v3: najlepsza dok≈Çadno≈õƒá dla polskiego."
        )

        st.divider()

        # 2. G≈Ç√≥wne zadania - najwa≈ºniejsze opcje NA WIERZCHU
        st.subheader("üõ†Ô∏è Co zrobiƒá?")
        do_transcribe = st.checkbox("Transkrypcja (Whisper)", value=True)
        do_extraction = st.checkbox(
            "Ekstrakcja wiedzy (do Laboratorium)",
            value=True,
            help="Analizuje transkrypcjƒô i wyciƒÖga kluczowe pojƒôcia, narzƒôdzia i wskaz√≥wki. Wymagane do generowania notatek w Laboratorium."
        )
        do_summarize = st.checkbox("Podsumowanie (LLM)", value=False)

        st.divider()

        # 3. Ustawienia wyj≈õcia - czƒôsto u≈ºywane
        st.subheader("üìÇ Gdzie zapisaƒá?")
        output_path = st.text_input("Folder zapisu:", value=os.path.abspath(DATA_OUTPUT))
        output_format = st.selectbox(
            "Format transkrypcji:",
            options=["json", "txt", "txt_no_timestamps", "srt", "vtt"],
            help="json: bazowy format (zalecany), txt: z timestampami, srt/vtt: napisy"
        )

        # 4. Opcje zaawansowane - ukryte
        with st.expander("‚öôÔ∏è Opcje zaawansowane", expanded=False):
            download_subs = st.checkbox("Pobierz napisy YT (je≈õli sƒÖ)", value=True)
            summary_style = st.selectbox(
                "Styl podsumowania:",
                options=["Zwiƒôz≈Çe (3 punkty)", "Kr√≥tkie (1 akapit)", "Szczeg√≥≈Çowe (Pe≈Çne)"]
            )
            yt_quality = st.selectbox("Jako≈õƒá pobierania YT:", ["best", "audio_only", "worst"])
            audio_bitrate = "128k"
            obsidian_vault = st.text_input("Vault Obsidian:", value="", help="Opcjonalne - ≈õcie≈ºka do vault Obsidian")

            st.divider()
            if st.button("üßπ Zwolnij VRAM", use_container_width=True):
                from src.utils.config import MODEL_WRITER
                unload_model(MODEL_EXTRACTOR)
                unload_model(MODEL_WRITER)
                st.toast("Pamiƒôƒá VRAM zosta≈Ça wyczyszczona!", icon="üßπ")

        # Status FFmpeg - na dole
        st.divider()
        ffmpeg_ok, _ = check_ffmpeg()
        if ffmpeg_ok:
            st.success("FFmpeg: OK", icon="‚úÖ")
        else:
            st.error("FFmpeg: BRAK - wymagany do konwersji audio!", icon="‚ö†Ô∏è")

    # Dzielimy aplikacjƒô na dwie g≈Ç√≥wne zak≈Çadki
    tab_main, tab_lab = st.tabs(["üìÇ Przetwarzanie Audio", "‚úçÔ∏è Laboratorium Tekstu"])

    # --- TAB 1: Przetwarzanie Audio ---
    with tab_main:
        st.header("Nowa Transkrypcja")
        
        col_t1, col_t2 = st.columns(2)
        with col_t1:
            st.subheader("üì∫ YouTube")
            yt_url = st.text_input(
                "Wklej link do YouTube:",
                key="yt_url_input",
                placeholder="https://www.youtube.com/watch?v=...",
                help="Wklej pe≈Çny link do filmu YouTube"
            )
            start_yt = st.button("üöÄ Start YouTube", type="primary", disabled=not yt_url)
            
        with col_t2:
            st.subheader("üìÇ Plik Lokalny")
            uploaded_files = st.file_uploader(
                "Wybierz pliki (mo≈ºesz przeciƒÖgnƒÖƒá lub wybraƒá wiele):",
                type=["mp4", "mp3", "m4a", "wav", "mkv", "avi"],
                accept_multiple_files=True,
                help="PrzeciƒÖgnij pliki lub kliknij aby wybraƒá. Obs≈Çugiwane: MP4, MP3, M4A, WAV, MKV, AVI"
            )

            # Poka≈º listƒô wybranych plik√≥w
            if uploaded_files:
                st.caption(f"Wybrano {len(uploaded_files)} plik(√≥w): {', '.join([f.name for f in uploaded_files[:3]])}{'...' if len(uploaded_files) > 3 else ''}")

            # Sprawd≈∫ czy wszystkie pliki to ju≈º MP3
            all_mp3 = uploaded_files and all(f.name.lower().endswith('.mp3') for f in uploaded_files)
            if not all_mp3:
                convert_to_mp3 = st.checkbox("Konwertuj na MP3", value=True)
            else:
                convert_to_mp3 = False

            start_local = st.button("üöÄ Start Plik Lokalny", type="primary", disabled=not uploaded_files)

        # Logika przetwarzania dla Tab 1
        if start_yt or start_local:
            st.divider()
            progress_bar = st.progress(0.0)
            status_text = st.empty()
            progress_tracker = StreamlitProgress(progress_bar, status_text)
            stop_event = threading.Event()
            
            processor = ContentProcessor(logger, stop_event, progress_tracker.update)
            
            try:
                with st.status("ü§ñ Przetwarzanie...", expanded=True) as status:
                    results = []

                    if start_yt:
                        # YouTube - pojedynczy link
                        downloaded_items = processor.download_video(yt_url, output_path, yt_quality, audio_bitrate.replace('k', ''))
                        if downloaded_items:
                            item = downloaded_items[0]
                            target_file_path = item.get('video') if isinstance(item, dict) else item
                            subtitle_path = item.get('subtitles') if isinstance(item, dict) else None

                            txt_file, json_file = _process_single_file(
                                processor, target_file_path, subtitle_path, output_path,
                                download_subs, do_transcribe, do_summarize,
                                WHISPER_LANGUAGES[language], model_size, output_format, summary_style
                            )
                            if txt_file:
                                results.append(txt_file)
                            if json_file:
                                st.success(f"üì¶ Bazowy JSON: `{os.path.basename(json_file)}`")
                    else:
                        # Pliki lokalne - obs≈Çuga wielu
                        total_files = len(uploaded_files)
                        for idx, uploaded_file in enumerate(uploaded_files, 1):
                            st.write(f"üìÑ Przetwarzanie ({idx}/{total_files}): **{uploaded_file.name}**")

                            target_file_path = os.path.join(output_path, uploaded_file.name)
                            with open(target_file_path, "wb") as f:
                                f.write(uploaded_file.getbuffer())

                            if convert_to_mp3 and not uploaded_file.name.lower().endswith('.mp3'):
                                mp3_path = os.path.join(output_path, os.path.splitext(uploaded_file.name)[0] + ".mp3")
                                target_file_path = processor.convert_to_mp3(target_file_path, mp3_path)

                            txt_file, json_file = _process_single_file(
                                processor, target_file_path, None, output_path,
                                False, do_transcribe, do_summarize,
                                WHISPER_LANGUAGES[language], model_size, output_format, summary_style
                            )
                            if txt_file:
                                results.append(txt_file)
                            if json_file:
                                st.success(f"üì¶ Bazowy JSON: `{os.path.basename(json_file)}`")

                    if results:
                        st.session_state['last_generated_result'] = results[-1]

                        # === EKSTRAKCJA WIEDZY ===
                        extraction_results = []
                        if do_extraction and results:
                            st.write("---")
                            st.write("üß† **Etap 2: Ekstrakcja wiedzy**")
                            extraction_progress = st.progress(0.0)
                            extraction_status = st.empty()

                            for txt_file in results:
                                extraction_status.text(f"Analizujƒô: {os.path.basename(txt_file)}...")
                                json_path = _run_knowledge_extraction(txt_file, extraction_progress, extraction_status)
                                if json_path:
                                    extraction_results.append(json_path)
                                    # Zapisz do session state
                                    st.session_state['last_extraction_json'] = json_path
                                    st.session_state['last_topic_name'] = _extract_topic_from_filename(txt_file)

                        # === PODSUMOWANIE ===
                        status.update(label=f"‚úÖ Gotowe! Przetworzono {len(results)} plik(√≥w)", state="complete", expanded=False)

                        for r in results:
                            st.success(f"üìù Transkrypcja: `{os.path.basename(r)}`")

                        if extraction_results:
                            for e in extraction_results:
                                st.success(f"üß† Baza wiedzy: `{os.path.basename(e)}`")

                            # Przycisk przej≈õcia do Laboratorium
                            st.divider()
                            st.info("‚ú® **Gotowe do generowania notatek!** Kliknij poni≈ºej, aby przej≈õƒá do Laboratorium Tekstu.")

                            if st.button("üöÄ Przejd≈∫ do Laboratorium Tekstu", type="primary", use_container_width=True):
                                st.session_state['go_to_lab'] = True
                                st.rerun()

            except Exception as e:
                st.error(f"‚ùå B≈ÇƒÖd: {e}")

    # --- TAB 2: NOWA FUNKCJONALNO≈öƒÜ (Laboratorium Tekstu) ---
    with tab_lab:
        st.header("‚úçÔ∏è Generator i Edytor Notatek")

        # Kr√≥tki opis dla u≈ºytkownika
        st.caption("Tw√≥rz profesjonalne notatki na podstawie transkrypcji. Wybierz styl, edytuj i eksportuj do Obsidian.")

        # Inicjalizacja session state dla edytowalnego wyniku
        if 'generated_content' not in st.session_state:
            st.session_state['generated_content'] = None
        if 'current_output_filename' not in st.session_state:
            st.session_state['current_output_filename'] = None

        # =====================================================
        # KROK 1: WYB√ìR ≈πR√ìD≈ÅA
        # =====================================================
        st.subheader("üìÇ Krok 1: Wybierz ≈∫r√≥d≈Ço danych")

        json_files = glob.glob(os.path.join(DATA_PROCESSED, "*.json"))
        json_files.sort(key=os.path.getmtime, reverse=True)

        if not json_files:
            st.info(
                "**Jak zaczƒÖƒá?**\n\n"
                "1. Przejd≈∫ do zak≈Çadki **üìÇ Przetwarzanie Audio**\n"
                "2. Wklej link YouTube lub wybierz plik lokalny\n"
                "3. Upewnij siƒô, ≈ºe opcja **Ekstrakcja wiedzy** jest zaznaczona\n"
                "4. Kliknij **Start** - po zako≈Ñczeniu pliki JSON pojawiƒÖ siƒô tutaj automatycznie"
            )
        else:
            # Automatycznie wybierz ostatni plik z ekstrakcji je≈õli istnieje
            default_index = 0
            if st.session_state.get('last_extraction_json'):
                last_json = st.session_state['last_extraction_json']
                if last_json in json_files:
                    default_index = json_files.index(last_json)

            # Poka≈º komunikat je≈õli przyszli≈õmy z przycisku "Przejd≈∫ do Laboratorium"
            if st.session_state.get('go_to_lab'):
                st.success("‚ú® ≈öwie≈ºa baza wiedzy gotowa! Wybierz styl i wygeneruj notatkƒô.")
                st.session_state['go_to_lab'] = False

            selected_file = st.selectbox(
                "Baza wiedzy (plik JSON):",
                json_files,
                index=default_index,
                format_func=lambda x: os.path.basename(x)
            )

            if selected_file:
                # ≈Åadowanie danych
                with open(selected_file, 'r', encoding='utf-8') as f:
                    knowledge_data = json.load(f)

                # =====================================================
                # P1: PODGLƒÑD KONTEKSTU
                # =====================================================
                # Zliczanie element√≥w
                all_concepts = []
                all_tools = []
                all_tips = []
                all_topics = set()

                for item in knowledge_data:
                    if 'key_concepts' in item:
                        all_concepts.extend(item['key_concepts'])
                    if 'tools' in item:
                        all_tools.extend(item['tools'])
                    if 'tips' in item:
                        all_tips.extend(item['tips'])
                    if 'topics' in item:
                        all_topics.update(item['topics'])

                # Metryki
                col_m1, col_m2, col_m3, col_m4 = st.columns(4)
                col_m1.metric("üìä Segmenty", len(knowledge_data))
                col_m2.metric("üí° Pojƒôcia", len(all_concepts))
                col_m3.metric("üîß Narzƒôdzia", len(all_tools))
                col_m4.metric("üìå Wskaz√≥wki", len(all_tips))

                # PodglƒÖd danych w expander
                with st.expander("üîç PodglƒÖd wyekstrahowanych danych", expanded=False):
                    preview_col1, preview_col2 = st.columns(2)

                    with preview_col1:
                        st.markdown("**Kluczowe pojƒôcia:**")
                        for concept in all_concepts[:5]:
                            st.markdown(f"- **{concept.get('term', 'N/A')}**: {concept.get('definition', '')[:80]}...")
                        if len(all_concepts) > 5:
                            st.caption(f"... i {len(all_concepts) - 5} wiƒôcej")

                    with preview_col2:
                        st.markdown("**Narzƒôdzia:**")
                        for tool in all_tools[:5]:
                            st.markdown(f"- **{tool.get('name', 'N/A')}**: {tool.get('description', '')[:60]}...")
                        if len(all_tools) > 5:
                            st.caption(f"... i {len(all_tools) - 5} wiƒôcej")

                    st.markdown("**Tematy/Tagi:**")
                    st.write(", ".join(list(all_topics)[:15]))

                st.divider()

                # =====================================================
                # KROK 2: WYB√ìR STYLU (P2: Radio buttons z opisami)
                # =====================================================
                st.subheader("üé® Krok 2: Wybierz styl notatki")

                # Opisy styl√≥w do wy≈õwietlenia
                style_descriptions = {
                    "standard": "Zbalansowany, edukacyjny. TL;DR na g√≥rze, Wikilinks [[Termin]], kr√≥tkie akapity.",
                    "academic": "Formalny, analityczny. Pe≈Çne akapity prozy, g≈Çƒôboka analiza relacji, bogate s≈Çownictwo.",
                    "blog": "Lu≈∫ny, bezpo≈õredni. Emotikony, chwytliwe nag≈Ç√≥wki, storytelling, praktyczne use-cases."
                }

                style_cols = st.columns(3)

                # Radio button dla wyboru stylu
                selected_mode = st.radio(
                    "Styl:",
                    options=list(PROMPT_TEMPLATES.keys()),
                    format_func=lambda x: PROMPT_TEMPLATES[x]["name"],
                    horizontal=True,
                    label_visibility="collapsed"
                )

                # Wy≈õwietl opis wybranego stylu
                st.info(f"**{PROMPT_TEMPLATES[selected_mode]['name']}**: {style_descriptions.get(selected_mode, '')}")

                st.divider()

                # =====================================================
                # KROK 3: TEMAT
                # =====================================================
                st.subheader("üìù Krok 3: Temat notatki")

                # U≈ºyj topic z session state (je≈õli w≈Ça≈õnie przyszed≈Ç z ekstrakcji) lub wyciƒÖgnij z nazwy pliku
                if st.session_state.get('last_topic_name') and st.session_state.get('last_extraction_json') == selected_file:
                    auto_topic = st.session_state['last_topic_name']
                else:
                    auto_topic = _extract_topic_from_filename(selected_file)

                topic_name = st.text_input("Temat:", value=auto_topic, label_visibility="collapsed")

                # =====================================================
                # P1: EXPANDER DLA PROMPT√ìW (Zaawansowane)
                # =====================================================
                default_sys = PROMPT_TEMPLATES[selected_mode]["system"]
                default_user = PROMPT_TEMPLATES[selected_mode]["user"]

                with st.expander("‚öôÔ∏è Zaawansowane: Edycja Prompt√≥w", expanded=False):
                    st.caption("Edytuj prompty tylko je≈õli wiesz co robisz. Zmienne: `{topic_name}`, `{context_items}`")

                    edited_system = st.text_area(
                        "System Prompt (Rola AI):",
                        value=default_sys,
                        height=180,
                        key="system_prompt_editor"
                    )
                    edited_user = st.text_area(
                        "User Prompt (Zadanie):",
                        value=default_user,
                        height=120,
                        key="user_prompt_editor"
                    )

                    # Walidacja placeholder√≥w
                    if "{context_items}" not in edited_user:
                        st.warning("‚ö†Ô∏è Brak `{context_items}` w User Prompt - notatka bƒôdzie bez danych ≈∫r√≥d≈Çowych!")
                    if "{topic_name}" not in edited_user:
                        st.warning("‚ö†Ô∏è Brak `{topic_name}` w User Prompt - temat nie zostanie przekazany do LLM.")

                    col_reset, _ = st.columns([1, 3])
                    with col_reset:
                        if st.button("üîÑ Przywr√≥ƒá domy≈õlne", key="reset_prompts"):
                            st.rerun()

                st.divider()

                # =====================================================
                # PRZYCISK GENEROWANIA
                # =====================================================
                gen_col1, gen_col2 = st.columns([2, 1])
                with gen_col1:
                    generate_btn = st.button("üöÄ Generuj Notatkƒô", type="primary", use_container_width=True)
                with gen_col2:
                    st.caption("Model: Bielik 11B (~30-60s)")

                if generate_btn:
                    writer = ReportWriter()

                    # Streaming z live preview
                    st.write("---")
                    st.write("üß† **Bielik generuje notatkƒô...**")
                    stream_placeholder = st.empty()
                    stream_status = st.empty()

                    streamed_content = []
                    token_count = [0]  # Lista dla closure

                    def stream_to_ui(token: str):
                        """Callback wywo≈Çywany dla ka≈ºdego tokena."""
                        streamed_content.append(token)
                        token_count[0] += 1

                        # Aktualizuj podglƒÖd co 5 token√≥w (dla wydajno≈õci)
                        if token_count[0] % 5 == 0:
                            stream_placeholder.markdown("".join(streamed_content) + "‚ñå")
                            stream_status.caption(f"Generowanie... ({token_count[0]} token√≥w)")

                    final_md = writer.generate_chapter(
                        topic_name=topic_name,
                        aggregated_data=knowledge_data,
                        mode=selected_mode,
                        custom_system_prompt=edited_system,
                        custom_user_prompt=edited_user,
                        stream_callback=stream_to_ui
                    )

                    # Wyczy≈õƒá placeholdery po zako≈Ñczeniu
                    stream_placeholder.empty()
                    stream_status.empty()

                    # Zapisz do session state
                    st.session_state['generated_content'] = final_md
                    st.session_state['current_output_filename'] = os.path.basename(selected_file).replace(".json", f"_{selected_mode}.md")
                    st.success(f"‚úÖ Wygenerowano notatkƒô! ({token_count[0]} token√≥w)")
                    st.rerun()

                # =====================================================
                # P2: EDYTOWALNY WYNIK PRZED ZAPISEM
                # =====================================================
                if st.session_state['generated_content']:
                    st.divider()
                    st.subheader("üìù Wynik (edytowalny)")

                    # Tabs dla podglƒÖdu vs edycji
                    view_tab, edit_tab = st.tabs(["üëÅÔ∏è PodglƒÖd", "‚úèÔ∏è Edycja"])

                    with view_tab:
                        st.markdown(st.session_state['generated_content'])

                    with edit_tab:
                        edited_content = st.text_area(
                            "Edytuj markdown przed zapisem:",
                            value=st.session_state['generated_content'],
                            height=400,
                            key="result_editor",
                            label_visibility="collapsed"
                        )
                        # Aktualizuj session state je≈õli edytowano
                        if edited_content != st.session_state['generated_content']:
                            st.session_state['generated_content'] = edited_content

                    # Przyciski akcji
                    st.divider()
                    action_col1, action_col2, action_col3, action_col4 = st.columns(4)

                    output_filename = st.session_state['current_output_filename']
                    save_path = os.path.join(DATA_OUTPUT, output_filename)
                    content_to_save = st.session_state['generated_content']

                    with action_col1:
                        if st.button("üíæ Zapisz lokalnie", use_container_width=True):
                            with open(save_path, "w", encoding="utf-8") as f:
                                f.write(content_to_save)
                            st.success(f"Zapisano: {output_filename}")

                    with action_col2:
                        st.download_button(
                            "üì• Pobierz .md",
                            content_to_save,
                            file_name=output_filename,
                            use_container_width=True
                        )

                    with action_col3:
                        if obsidian_vault:
                            if st.button("üì¶ ‚Üí Obsidian", use_container_width=True):
                                try:
                                    # Zapisz lokalnie najpierw
                                    with open(save_path, "w", encoding="utf-8") as f:
                                        f.write(content_to_save)
                                    shutil.copy(save_path, Path(obsidian_vault) / output_filename)
                                    st.success("Skopiowano do Obsidian!")
                                except Exception as e:
                                    st.error(f"B≈ÇƒÖd: {e}")
                        else:
                            st.button("üì¶ ‚Üí Obsidian", disabled=True, use_container_width=True, help="Ustaw ≈õcie≈ºkƒô Vault w sidebarze")

                    with action_col4:
                        if st.button("üóëÔ∏è Wyczy≈õƒá", use_container_width=True):
                            st.session_state['generated_content'] = None
                            st.session_state['current_output_filename'] = None
                            st.rerun()

    # --- Logi na dole strony (w expander) ---
    with st.expander("üìã Logi systemowe", expanded=False):
        if os.path.exists("app_debug.log"):
            if st.button("üîÑ Od≈õwie≈º logi"):
                st.rerun()
            with open("app_debug.log", "r", encoding="utf-8") as f:
                logs = f.readlines()[-30:]
            st.code("".join(logs), language="log")
        else:
            st.caption("Brak pliku log√≥w (app_debug.log)")


if __name__ == "__main__":
    main()
